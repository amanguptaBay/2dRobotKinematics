{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Showing Robot Using Geometry\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(-0.9999999999999999, 1.0000000000000002)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Define the joint angles and link lengths\n",
    "theta1 = np.pi/2\n",
    "theta2 = np.pi/2\n",
    "L1 = 1\n",
    "L2 = 1\n",
    "def plotRobot(L1, L2, theta1, theta2):\n",
    "    x1 = L1*np.cos(theta1)\n",
    "    y1 = L1*np.sin(theta1)\n",
    "    x2 = x1 + L2*np.cos(theta1+theta2)\n",
    "    y2 = y1 + L2*np.sin(theta1+theta2)\n",
    "\n",
    "    fig, ax = plt.subplots()\n",
    "    ax.plot([0, x1], [0, y1], 'b-', lw=2)  # First link\n",
    "    ax.plot([x1, x2], [y1, y2], 'r-', lw=2)  # Second link\n",
    "    ax.set_aspect('equal')\n",
    "    print(\"Showing Robot Using Geometry\")\n",
    "    plt.show()\n",
    "    return x2,y2\n",
    "GROUND_TRUTH = plotRobot(L1, L2, theta1, theta2)\n",
    "print(GROUND_TRUTH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def TP(x,y):\n",
    "    \"\"\"\n",
    "        Prismatic Transformation by x,y\n",
    "    \"\"\"\n",
    "    return np.array([[1,0,x],[0,1,y],[0,0,1]])\n",
    "def TPx(x):\n",
    "    return TP(x,0)\n",
    "def TR(A):\n",
    "    \"\"\"\n",
    "        Resolute Transformation by thetA\n",
    "    \"\"\"\n",
    "    return np.array([[np.cos(A), -np.sin(A), 0],[np.sin(A), np.cos(A), 0],[0,0,1]])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Thinking:\n",
    "![2d_forward_kinematics_thought_process](assets/2d_forward_kinematics_thought_process.png)\n",
    "*Step by Step how I got this result*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-1.,  1.,  1.])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Result from the equation (note how we start at the origin)\n",
    "myResult = TR(theta1)@TPx(L1)@TR(theta2)@TPx(L2)@np.array([0,0,1])\n",
    "myResult"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Showing the Ground Truth with extra rotation dimension"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[-0.9999999999999999, 1.0000000000000002, 1]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = list(GROUND_TRUTH) #We add a 1 since the original ground truth doesnt have a rotation dimension\n",
    "x.append(1)\n",
    "x"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "They are equivalent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.all(np.isclose(x,myResult))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PyTorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "def TP(x,y):\n",
    "    \"\"\"\n",
    "        Prismatic Transformation by x,y\n",
    "    \"\"\"\n",
    "    processed = list()\n",
    "    for i in [0.0,0.0,x,0.0,1.0,y,0.0,0.0,1.0]:\n",
    "        if isinstance(i, float):\n",
    "            processed.append(torch.tensor(i).view(1))\n",
    "        else:\n",
    "            processed.append(i.view(1))\n",
    "    return torch.cat(tuple(processed)).view(3,3)\n",
    "\n",
    "def TPx(x):\n",
    "    return TP(x,torch.tensor(0.0))\n",
    "\n",
    "def TR(A):\n",
    "    \"\"\"\n",
    "        Resolute Transformation by theta\n",
    "    \"\"\"\n",
    "    processed = list()\n",
    "    for i in [torch.cos(A), -torch.sin(A), 0,torch.sin(A), torch.cos(A), 0,0,0,1]:\n",
    "        if isinstance(i, (int, float)):\n",
    "            processed.append(torch.tensor(i).view(1))\n",
    "        else:\n",
    "            processed.append(i.view(1))\n",
    "\n",
    "    return torch.cat(tuple(processed)).view(3,3)\n",
    "\n",
    "#Result from the equation (note how we start at the origin)\n",
    "#start = torch.tensor([0.0,0.0,1.0], requires_grad=True).unsqueeze(1)\n",
    "#myResult = TR(theta1)\n",
    "#myResult = myResult@TPx(L1)\n",
    "#myResult = myResult@TR(theta2)@TPx(L2)@start\n",
    "#myResult"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'int' object has no attribute 'view'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_123066/3270990889.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mL1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1.0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrequires_grad\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mTR\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mL1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/tmp/ipykernel_123066/4254110739.py\u001b[0m in \u001b[0;36mTR\u001b[0;34m(A)\u001b[0m\n\u001b[1;32m     26\u001b[0m             \u001b[0mprocessed\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 28\u001b[0;31m             \u001b[0mprocessed\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     29\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprocessed\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'int' object has no attribute 'view'"
     ]
    }
   ],
   "source": [
    "L1 = torch.tensor(1.0, requires_grad=True)\n",
    "\n",
    "TR(L1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-1.        ,  0.99999994,  1.        ], dtype=float32)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "myResult = myResult.squeeze().detach().numpy()\n",
    "myResult"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ True,  True,  True])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.isclose(myResult, x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def forward_kinematics(theta1,theta2):\n",
    "    start = torch.tensor([0.0,0.0,1.0]).unsqueeze(1)\n",
    "    myResult = TR(theta1)\n",
    "    myResult = myResult@TPx(L1)\n",
    "    myResult = myResult@TR(theta2)@TPx(L2)@start\n",
    "    return myResult"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[2.],\n",
       "        [0.],\n",
       "        [1.]])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "theta1 = torch.tensor(0.0, requires_grad=True)\n",
    "theta2 = torch.tensor(0.0, requires_grad=True)\n",
    "\n",
    "L1 = torch.tensor(1.0)\n",
    "L2 = torch.tensor(1.0)\n",
    "\n",
    "forward_kinematics(theta1,theta2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "DEEPLABCUT",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
